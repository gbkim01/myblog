<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R | 日常茶飯事</title>
    <link>/myblog/categories/r/</link>
      <atom:link href="/myblog/categories/r/index.xml" rel="self" type="application/rss+xml" />
    <description>R</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019</copyright><lastBuildDate>Fri, 04 Oct 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/myblog/img/icon-192.png</url>
      <title>R</title>
      <link>/myblog/categories/r/</link>
    </image>
    
    <item>
      <title>데이터 프레임에서 짝수행과 홀수행 선별하는 다른 방법</title>
      <link>/myblog/post/%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%84%EB%A0%88%EC%9E%84%EC%97%90%EC%84%9C-%EC%A7%9D%EC%88%98%ED%96%89%EA%B3%BC-%ED%99%80%EC%88%98%ED%96%89-%EC%84%A0%EB%B3%84%ED%95%98%EB%8A%94-%EB%8B%A4%EB%A5%B8-%EB%B0%A9%EB%B2%95/</link>
      <pubDate>Fri, 04 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/myblog/post/%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%84%EB%A0%88%EC%9E%84%EC%97%90%EC%84%9C-%EC%A7%9D%EC%88%98%ED%96%89%EA%B3%BC-%ED%99%80%EC%88%98%ED%96%89-%EC%84%A0%EB%B3%84%ED%95%98%EB%8A%94-%EB%8B%A4%EB%A5%B8-%EB%B0%A9%EB%B2%95/</guid>
      <description>


&lt;p&gt;데이터 프레임에서 짝수행과 홀수행을 구분하는 더 간단한 방법이 있어서 메모할 겸 올려본다.&lt;/p&gt;
&lt;p&gt;TRUE, FALSE 논리연산을 이용한 방법이 가장 간단해 보인다. 응용하면 짝수열과 홀수열도 간단히 선택할 수 있다.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## 데이터셋 구성
a &amp;lt;- rnorm(99)
b &amp;lt;- runif(99)
c &amp;lt;- rnorm(99)
d &amp;lt;- runif(99)
e &amp;lt;- rnorm(99)
f &amp;lt;- runif(99)
g &amp;lt;- rnorm(99)
h &amp;lt;- runif(99)
i &amp;lt;- rnorm(99)
j &amp;lt;- runif(99)
dt &amp;lt;-data.frame(a,b,c,d,e,f,g,h,i,j)

## 필요한 행 선택하기
dt[c(TRUE, FALSE), ]  # (1, 3, 5, 7... 행 선택)
dt[c(FALSE, TRUE), ]  # (2, 4, 6, 7... 행 선택)
dt[c(TRUE, FALSE, FALSE), ]  # (1, 4, 7, 10...행 선택)
dt[c(TRUE, FALSE, FALSE, FALSE, FALSE), ]

## 필요한 열 선택하기
dt[ ,c(TRUE, FALSE)]  # (1, 3, 5, 7... 열 선택)
dt[ ,c(FALSE, TRUE)]  # (2, 4, 6, 7... 열 선택)
dt[ ,c(TRUE, FALSE, FALSE)] # (1, 4, 7, 10...열 선택)
dt[ ,c(TRUE, FALSE, FALSE, FALSE, FALSE)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;seq()&lt;/strong&gt;함수를 이용하지 않고 &lt;strong&gt;열 번호(row_number)&lt;/strong&gt;를 2로 나눈 나머지를 이용하여 선별할 수도 있다.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- data.frame(V1 = seq(26), V2 = letters)

df %&amp;gt;% filter(row_number() %% 2 == 0) ## 짝수열 
df %&amp;gt;% filter(row_number() %% 2 == 1) ## 홀수열
df %&amp;gt;% filter(row_number() %% 3 == 1)&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>데이터셋의 짝수행과 홀수행 구분</title>
      <link>/myblog/post/%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%84%EB%A0%88%EC%9E%84%EC%97%90%EC%84%9C-%EC%A7%9D%EC%88%98%ED%96%89%EA%B3%BC-%ED%99%80%EC%88%98%ED%96%89-%EC%84%A0%EB%B3%84%ED%95%98%EA%B8%B0/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/myblog/post/%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%94%84%EB%A0%88%EC%9E%84%EC%97%90%EC%84%9C-%EC%A7%9D%EC%88%98%ED%96%89%EA%B3%BC-%ED%99%80%EC%88%98%ED%96%89-%EC%84%A0%EB%B3%84%ED%95%98%EA%B8%B0/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;https://youtu.be/w7Q_eKN5r-I?t=136&#34;&gt;유투브&lt;/a&gt;에서 말하길, &lt;strong&gt;파이썬&lt;/strong&gt;을 이용하면 모듈과 자료를 불러들이는 과정을 포함하여 단 세 줄의 코드로 데이터셋에서 짝수행을 뽑을수 있다고 한다. &lt;strong&gt;R&lt;/strong&gt;에서도 할 수 있겠다 싶어 머리를 굴려봤다.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
data &amp;lt;- read.csv(&amp;quot;filename&amp;quot;)
data_even &amp;lt;- filter(data, seq_len(nrow(data))%% 2==0) # 짝수행
data_odd &amp;lt;- filter(data, seq_len(nrow(data))%% 2==1) # 홀수행&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;위의 코드를 단계별로 설명하면,&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;seq_len()&lt;/strong&gt; 함수를 이용하여 데이터 테이블의 마지막 행 까지 인덱스를 부여&lt;/li&gt;
&lt;li&gt;각각의 인덱스를 2로 나눈 나머지가 0인 행과 1인 행을 각각 필터링&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;위 두 단계를 거쳐 짝수행과 홀수행을 구분하였다. 파이썬 만큼 깔끔하지는 않지만 어쨌든 패키지를 불러와서 짝수행을 뽑는 것 까지 3~4줄의 &lt;strong&gt;R&lt;/strong&gt;코드면 된다.&lt;/p&gt;
&lt;p&gt;이 방법을 이용해서 &lt;a href=&#34;http://www.ypec.re.kr/modedg/contentsView.do?ucont_id=CTX000007&amp;amp;srch_menu_nix=t7W3a9w7&#34;&gt;&lt;strong&gt;청소년정책분석평가센터&lt;/strong&gt;&lt;/a&gt;가 매년 공개하는 청소년정책성과(청소년의 삶의질, 청소년참여활동수준) 점수를 하나의 테이블로 간단히 정리하였다. 연도별 17개 시도의 성과정보를 스크래핑 하는 코드는 &lt;a href=&#34;https://github.com/gbkim01/web_scraping_with_R/blob/master/2_%EC%97%B0%EB%8F%84%EB%B3%84%EC%B2%AD%EC%86%8C%EB%85%84%EC%A0%95%EC%B1%85%EC%84%B1%EA%B3%BC.R&#34;&gt;&lt;strong&gt;Github&lt;/strong&gt;&lt;/a&gt;에 올렸다.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>URL 리스트 취합</title>
      <link>/myblog/post/web-scraping-with-r-www-climatewatchdata-org/</link>
      <pubDate>Sun, 29 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/myblog/post/web-scraping-with-r-www-climatewatchdata-org/</guid>
      <description>


&lt;p&gt;웹 스크래핑은 타겟이 되는 인터넷 페이지의 url을 확인하는 것으로 시작한다. 한두 개의 웹페이지라면 모르겠지만 스크래핑 대상물이 여러 페이지에 흩어져 있다면 인터넷 주소를 취합하는 간단한 작업도 초보자에겐 큰 장애물이 된다. 그러나 문법이 조금 익숙한 사용자라면 반복문을 사용하여 좀 더 간편하게 필요한 url 리스트를 구성할 수 있다. 통상의 웹페이지 주소는 main URl에 인덱스가 붙는 형식으로 구성되어 있기 때문이다. 예컨데 이렇게 말이다.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;main &amp;lt;- &amp;quot;www.main_url.co.kr/search=&amp;quot;
search &amp;lt;- c(&amp;quot;apple&amp;quot;, &amp;quot;orange&amp;quot;, &amp;quot;pineapple&amp;quot;)
index &amp;lt;- &amp;quot;&amp;amp;indexpage=&amp;quot;

url_list &amp;lt;- NULL

for (i in 1:3){
  for (j in 1:3) {
    url &amp;lt;- paste0(main, search[i], index, j)
    url_list &amp;lt;- append(url_list, url)
  }
}

url_list&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;www.main_url.co.kr/search=apple&amp;amp;indexpage=1&amp;quot;    
## [2] &amp;quot;www.main_url.co.kr/search=apple&amp;amp;indexpage=2&amp;quot;    
## [3] &amp;quot;www.main_url.co.kr/search=apple&amp;amp;indexpage=3&amp;quot;    
## [4] &amp;quot;www.main_url.co.kr/search=orange&amp;amp;indexpage=1&amp;quot;   
## [5] &amp;quot;www.main_url.co.kr/search=orange&amp;amp;indexpage=2&amp;quot;   
## [6] &amp;quot;www.main_url.co.kr/search=orange&amp;amp;indexpage=3&amp;quot;   
## [7] &amp;quot;www.main_url.co.kr/search=pineapple&amp;amp;indexpage=1&amp;quot;
## [8] &amp;quot;www.main_url.co.kr/search=pineapple&amp;amp;indexpage=2&amp;quot;
## [9] &amp;quot;www.main_url.co.kr/search=pineapple&amp;amp;indexpage=3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;climate-watch-data--&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;climate watch data의 페이지 구성&lt;/h3&gt;
&lt;center&gt;
&lt;img src = &#34;https://user-images.githubusercontent.com/30010992/66132557-36940600-e630-11e9-9982-e39c42dc0967.jpg&#34; width=80%&gt;
&lt;/center&gt;
&lt;p&gt;그러나 이번에 스크래핑한 &lt;a href=&#34;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information&#34;&gt;www.climatewatchdata.org&lt;/a&gt;는 웹페이지가 매우 독특한 구성으로 되어있어 위의 경우처럼 간단한 반복문으로는 url을 취합하기 어려웠다. 그림처럼 개별 섹션(Sectoral Mitication Targets) 및 섹터(Energy | Renewable Energy) 별로 해당되는 목록을 취합하기 위해서는 섹터 및 섹션별 url을 따로 만들어야 했는데 다음과 같은 복잡한 과정을 거쳐야 했기 때문이다.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;먼저 url &lt;em&gt;&lt;a href=&#34;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information&#34; class=&#34;uri&#34;&gt;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information&lt;/a&gt;&lt;/em&gt;로 들어가 총 5개의 섹션 리스트를 가져온다.&lt;/li&gt;
&lt;li&gt;각각의 섹션리스트를 모두 소문자로 변경하여 각 섹션별 주소를 구성한다. (ex: &lt;em&gt;&lt;a href=&#34;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=sectoral_mitigation_targets&#34; class=&#34;uri&#34;&gt;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=sectoral_mitigation_targets&lt;/a&gt;&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;각 섹션별로 모든 섹터 리스트(ex, Energy | Renewable Energy, Energy | Renewable Energy:Biofuels….)를 가져온다.&lt;/li&gt;
&lt;li&gt;모든 섹터 리스트를 기호 &lt;strong&gt;“|”&lt;/strong&gt; 를 기준으로 쪼갠 다음 &lt;strong&gt;“|”&lt;/strong&gt; 뒤에 위치하고 있는 문자를 소문자로 변경한다.&lt;/li&gt;
&lt;li&gt;위 4에서 만든 섹션을 가지고 각 섹션별 전체 주소리스트를 구성한다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;위의 5단계를 거쳐 최종적으로 만들어진 &lt;em&gt;&lt;a href=&#34;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=sectoral_mitigation_targets&amp;amp;sector=renewable_energy&#34; class=&#34;uri&#34;&gt;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=sectoral_mitigation_targets&amp;amp;sector=renewable_energy&lt;/a&gt;&lt;/em&gt;의 주소는 &lt;strong&gt;sectoral_mitication&lt;/strong&gt; 섹션의 &lt;strong&gt;renewable_energy&lt;/strong&gt;섹터의 목록을 스크래핑하는 기본 url이 된다.&lt;/p&gt;
&lt;p&gt;이상의 5가지 단계를 실행하기 위해 다음의 코드를 작성하였다.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;########### Section 취합 #############
### 1. 대문 page 이동
remDr$navigate(&amp;quot;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=none&amp;amp;sector=none&amp;quot;) 
## 대문 page source 읽기
html_page &amp;lt;- remDr$getPageSource()[[1]]

### 2. section 주소  : section_link 주소
section &amp;lt;- read_html(html_page) %&amp;gt;% html_nodes(&amp;quot;div.accordion-styles__title__2PD3i&amp;quot;) %&amp;gt;% html_text() 
section_adr &amp;lt;- str_replace_all(str_to_lower(section), &amp;quot; &amp;quot;, &amp;quot;_&amp;quot;) ##대문자 to 소문자, 공백을 &amp;quot;_&amp;quot;로 대체


########### 주소 취합 #############
main &amp;lt;- &amp;quot;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=&amp;quot;
section_sector &amp;lt;- NULL
link_list &amp;lt;- NULL

for (i in 1:length(section_adr)) {
  
  section_link &amp;lt;- paste0(main, section_adr[i], &amp;quot;&amp;amp;sector=none&amp;quot;)
  
  ### 3. sector 주소  : sector_link 주소
  remDr$navigate(section_link)
  Sys.sleep(3) # 3초 딜레이
  
  section_page &amp;lt;- remDr$getPageSource()[[1]]
  sector &amp;lt;- read_html(section_page) %&amp;gt;% html_nodes(&amp;quot;div.ndcs-country-accordion-styles__subAccordion__1zDx7&amp;quot;) %&amp;gt;% html_nodes(&amp;quot;div.accordion-styles__title__2PD3i&amp;quot;) %&amp;gt;% html_text() 
  
  link_list &amp;lt;- cbind(i, section[i], section_adr[i], sector)
  section_sector &amp;lt;- rbind(section_sector, link_list)
}

section_sector &amp;lt;- data.frame(section_sector)
names(section_sector) &amp;lt;- c(&amp;quot;index&amp;quot;, &amp;quot;section&amp;quot;, &amp;quot;section_adr&amp;quot;, &amp;quot;sector&amp;quot;)
section_sector$sector_adr &amp;lt;- str_to_lower(section_sector$sector)
section_sector$sector_adr &amp;lt;- str_split_fixed(section_sector$sector_adr, &amp;quot;[|]&amp;quot;, 2)[,2]
section_sector$sector_adr &amp;lt;- str_trim(section_sector$sector_adr)
section_sector$sector_adr &amp;lt;- str_replace_all(section_sector$sector_adr, &amp;quot;[-:/ ]&amp;quot;, &amp;quot;_&amp;quot;)
section_sector$sector_adr &amp;lt;- str_replace_all(section_sector$sector_adr, &amp;quot;__&amp;quot;, &amp;quot;_&amp;quot;)

### 주소 만들기
link_pool &amp;lt;- NULL
for (i in 1:dim(section_sector)[1]) {
  link &amp;lt;- paste0(main, section_sector$section_adr[i], &amp;quot;&amp;amp;sector=&amp;quot;, section_sector$sector_adr[i])
  link_pool &amp;lt;- append(link_pool, link)
}

section_sector &amp;lt;- cbind(section_sector, link_pool)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;참고로 해당 웹페이지가 java로 구성되었는지 &lt;strong&gt;rvest&lt;/strong&gt;로는 html 태그를 확인할 수 없었다. 차선책으로 &lt;strong&gt;Rselenium&lt;/strong&gt;을 사용하였으며 끊김없는 안정적인 스크래핑을 위해 중간중간 &lt;em&gt;Sys.sleep(3)&lt;/em&gt;의 코드를 추가하였다.&lt;/p&gt;
&lt;p&gt;이 외에 데이터를 취합하는 내용을 포함한 전체 코드는 &lt;a href=&#34;https://github.com/gbkim01/web_scraping_with_R/blob/master/1_climate_watch_data_org.R&#34;&gt;Github&lt;/a&gt;에 올려두었다.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
