---
title: 'URL 리스트 취합'
author: gbkim01
date: '2019-09-29'
slug: web-scraping-with-r-www-climatewatchdata-org
categories:
  - R
tags:
  - rvest
  - Rselenium
  - web scraping
---



<p>웹 스크래핑은 타겟이 되는 인터넷 페이지의 url을 확인하는 것으로 시작한다. 한두 개의 웹페이지라면 모르겠지만 스크래핑 대상물이 여러 페이지에 흩어져 있다면 인터넷 주소를 취합하는 간단한 작업도 초보자에겐 큰 장애물이 된다. 그러나 문법이 조금 익숙한 사용자라면 반복문을 사용하여 좀 더 간편하게 필요한 url 리스트를 구성할 수 있다. 통상의 웹페이지 주소는 main URl에 인덱스가 붙는 형식으로 구성되어 있기 때문이다. 예컨데 이렇게 말이다.</p>
<pre class="r"><code>main &lt;- &quot;www.main_url.co.kr/search=&quot;
search &lt;- c(&quot;apple&quot;, &quot;orange&quot;, &quot;pineapple&quot;)
index &lt;- &quot;&amp;indexpage=&quot;

url_list &lt;- NULL

for (i in 1:3){
  for (j in 1:3) {
    url &lt;- paste0(main, search[i], index, j)
    url_list &lt;- append(url_list, url)
  }
}

url_list</code></pre>
<pre><code>## [1] &quot;www.main_url.co.kr/search=apple&amp;indexpage=1&quot;    
## [2] &quot;www.main_url.co.kr/search=apple&amp;indexpage=2&quot;    
## [3] &quot;www.main_url.co.kr/search=apple&amp;indexpage=3&quot;    
## [4] &quot;www.main_url.co.kr/search=orange&amp;indexpage=1&quot;   
## [5] &quot;www.main_url.co.kr/search=orange&amp;indexpage=2&quot;   
## [6] &quot;www.main_url.co.kr/search=orange&amp;indexpage=3&quot;   
## [7] &quot;www.main_url.co.kr/search=pineapple&amp;indexpage=1&quot;
## [8] &quot;www.main_url.co.kr/search=pineapple&amp;indexpage=2&quot;
## [9] &quot;www.main_url.co.kr/search=pineapple&amp;indexpage=3&quot;</code></pre>
<div id="climate-watch-data--" class="section level3">
<h3>climate watch data의 페이지 구성</h3>
<center>
<img src = "https://user-images.githubusercontent.com/30010992/66132557-36940600-e630-11e9-9982-e39c42dc0967.jpg" width=80%>
</center>
<p>그러나 이번에 스크래핑한 <a href="https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information">www.climatewatchdata.org</a>는 웹페이지가 매우 독특한 구성으로 되어있어 위의 경우처럼 간단한 반복문으로는 url을 취합하기 어려웠다. 그림처럼 개별 섹션(Sectoral Mitication Targets) 및 섹터(Energy | Renewable Energy) 별로 해당되는 목록을 취합하기 위해서는 섹터 및 섹션별 url을 따로 만들어야 했는데 다음과 같은 복잡한 과정을 거쳐야 했기 때문이다.</p>
<ol style="list-style-type: decimal">
<li>먼저 url <em><a href="https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information" class="uri">https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information</a></em>로 들어가 총 5개의 섹션 리스트를 가져온다.</li>
<li>각각의 섹션리스트를 모두 소문자로 변경하여 각 섹션별 주소를 구성한다. (ex: <em><a href="https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=sectoral_mitigation_targets" class="uri">https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=sectoral_mitigation_targets</a></em>)</li>
<li>각 섹션별로 모든 섹터 리스트(ex, Energy | Renewable Energy, Energy | Renewable Energy:Biofuels….)를 가져온다.</li>
<li>모든 섹터 리스트를 기호 <strong>“|”</strong> 를 기준으로 쪼갠 다음 <strong>“|”</strong> 뒤에 위치하고 있는 문자를 소문자로 변경한다.</li>
<li>위 4에서 만든 섹션을 가지고 각 섹션별 전체 주소리스트를 구성한다.</li>
</ol>
<p>위의 5단계를 거쳐 최종적으로 만들어진 <em><a href="https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=sectoral_mitigation_targets&amp;sector=renewable_energy" class="uri">https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=sectoral_mitigation_targets&amp;sector=renewable_energy</a></em>의 주소는 <strong>sectoral_mitication</strong> 섹션의 <strong>renewable_energy</strong>섹터의 목록을 스크래핑하는 기본 url이 된다.</p>
<p>이상의 5가지 단계를 실행하기 위해 다음의 코드를 작성하였다.</p>
<pre class="r"><code>########### Section 취합 #############
### 1. 대문 page 이동
remDr$navigate(&quot;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=none&amp;sector=none&quot;) 
## 대문 page source 읽기
html_page &lt;- remDr$getPageSource()[[1]]

### 2. section 주소  : section_link 주소
section &lt;- read_html(html_page) %&gt;% html_nodes(&quot;div.accordion-styles__title__2PD3i&quot;) %&gt;% html_text() 
section_adr &lt;- str_replace_all(str_to_lower(section), &quot; &quot;, &quot;_&quot;) ##대문자 to 소문자, 공백을 &quot;_&quot;로 대체


########### 주소 취합 #############
main &lt;- &quot;https://www.climatewatchdata.org/ndcs/country/IND/sectoral-information?section=&quot;
section_sector &lt;- NULL
link_list &lt;- NULL

for (i in 1:length(section_adr)) {
  
  section_link &lt;- paste0(main, section_adr[i], &quot;&amp;sector=none&quot;)
  
  ### 3. sector 주소  : sector_link 주소
  remDr$navigate(section_link)
  Sys.sleep(3) # 3초 딜레이
  
  section_page &lt;- remDr$getPageSource()[[1]]
  sector &lt;- read_html(section_page) %&gt;% html_nodes(&quot;div.ndcs-country-accordion-styles__subAccordion__1zDx7&quot;) %&gt;% html_nodes(&quot;div.accordion-styles__title__2PD3i&quot;) %&gt;% html_text() 
  
  link_list &lt;- cbind(i, section[i], section_adr[i], sector)
  section_sector &lt;- rbind(section_sector, link_list)
}

section_sector &lt;- data.frame(section_sector)
names(section_sector) &lt;- c(&quot;index&quot;, &quot;section&quot;, &quot;section_adr&quot;, &quot;sector&quot;)
section_sector$sector_adr &lt;- str_to_lower(section_sector$sector)
section_sector$sector_adr &lt;- str_split_fixed(section_sector$sector_adr, &quot;[|]&quot;, 2)[,2]
section_sector$sector_adr &lt;- str_trim(section_sector$sector_adr)
section_sector$sector_adr &lt;- str_replace_all(section_sector$sector_adr, &quot;[-:/ ]&quot;, &quot;_&quot;)
section_sector$sector_adr &lt;- str_replace_all(section_sector$sector_adr, &quot;__&quot;, &quot;_&quot;)

### 주소 만들기
link_pool &lt;- NULL
for (i in 1:dim(section_sector)[1]) {
  link &lt;- paste0(main, section_sector$section_adr[i], &quot;&amp;sector=&quot;, section_sector$sector_adr[i])
  link_pool &lt;- append(link_pool, link)
}

section_sector &lt;- cbind(section_sector, link_pool)</code></pre>
<p>참고로 해당 웹페이지가 java로 구성되었는지 <strong>rvest</strong>로는 html 태그를 확인할 수 없었다. 차선책으로 <strong>Rselenium</strong>을 사용하였으며 끊김없는 안정적인 스크래핑을 위해 중간중간 <em>Sys.sleep(3)</em>의 코드를 추가하였다.</p>
<p>이 외에 데이터를 취합하는 내용을 포함한 전체 코드는 <a href="https://github.com/gbkim01/web_scraping_with_R/blob/master/1_climate_watch_data_org.R">Github</a>에 올려두었다.</p>
</div>
