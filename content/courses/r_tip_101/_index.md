---
title: 개요
author: 김강배
date: '2020-08-01'
categories:
  - class
linktitle: '2020 08 01 '
lastmod: '2020-08-01T20:39:08Z'
toc: yes
type: docs
menu:
  r_tip_101:
    name: 개요
    weight: 1
---
![](https://user-images.githubusercontent.com/30010992/89122878-fe867980-d505-11ea-812f-50da4890223b.png)



## **정리에 앞서...**

데이터 분석은 보통 다음의 세가지 단계를 거쳐 진행됩니다.

1. 자료의 취합과 정리
2. 자료 분석 및 가설검증
3. 분석결과의 정리 및 보고 

웹 크롤링은 위의 1단계에서 매우 유용하게 쓸 수 있는 방법입니다. 우리가 알고자 하는 분야에 대한 자료가 일목요연하게 정리되어 내 눈 앞에 있으면 좋으련만, 상당부분 그렇지 못한게 현실입니다. 목마른 자가 우물을 파듯이 대부분 직접 데이터를 구축해야 합니다. 

하지만 현실세계에서 데이터를 구축하는 것은 흔히들 생각하는 것보다 훨씬 많은 자원이 필요하고 개인이 감당하기에는 매우 벅찬 일입니다. 가령 100명을 대상으로 설문조사를 진행한다고 가정한다면... 생각만 해도 골치가 아픕니다. 

그래서 우리는 인터넷으로 눈을 돌립니다. 인테넷에는 우리가 생각하는 것 보다 훨씬 많은 자료들이 널려있습니다. 언론기사며 SNS, 공적기관의 연구결과 등등 인터넷에 떠도는 자료들을 모으는 것은 데이터 구축의 현실적인 대안이며, 그럴때 크롤링은 정말 유용한 수단이 됩니다.

여기 **Web Crawling with R**에서는 급하게 써먹을 수 있는 크롤링 방법을 정리합니다. 실제 현업에서 전문적으로 하시는 분들이 본다면 콧웃음 칠 내용이겠지만, 코딩과 무관한 삶을 살았던 사람들에게는 큰 도움이 될 것입니다. 개인적으로는 친한 선배가 파이썬으로 크롤링 하는 모습을 보며 신세계를 맛 봤는데, 저와 같은 문외한들에게 많은 도움이 되길 바랍니다. 

